---
title: 精通Python网络爬虫：核心技术、框架与项目实战
date: 
tags: [menu, python, 爬虫]
---
豆瓣书目
<!-- more -->
目录
前言
第一篇　理论基础篇
第1章　什么是网络爬虫 3
1.1　初识网络爬虫 3
1.2　为什么要学网络爬虫 4
1.3　网络爬虫的组成 5
1.4　网络爬虫的类型 6
1.5　爬虫扩展——聚焦爬虫 7
1.6　小结 8
第2章　网络爬虫技能总览 9
2.1　网络爬虫技能总览图 9
2.2　搜索引擎核心 10
2.3　用户爬虫的那些事儿 11
2.4　小结 12
第二篇　核心技术篇
第3章　网络爬虫实现原理与实现技术 15
3.1　网络爬虫实现原理详解 15
3.2　爬行策略 17
3.3　网页更新策略 18
3.4　网页分析算法 20
3.5　身份识别 21
3.6　网络爬虫实现技术 21
3.7　实例——metaseeker 22
3.8　小结 27
第4章　Urllib库与URLError异常处理 29
4.1　什么是Urllib库 29
4.2　快速使用Urllib爬取网页 30
4.3　浏览器的模拟——Headers属性 34
4.4　超时设置 37
4.5　HTTP协议请求实战 39
4.6　代理服务器的设置 44
4.7　DebugLog实战 45
4.8　异常处理神器——URLError实战 46
4.9　小结 51
第5章　正则表达式与Cookie的使用 52
5.1　什么是正则表达式 52
5.2　正则表达式基础知识 52
5.3　正则表达式常见函数 61
5.4　常见实例解析 64
5.5　什么是Cookie 66
5.6　Cookiejar实战精析 66
5.7　小结 71
第6章　手写Python爬虫 73
6.1　图片爬虫实战 73
6.2　链接爬虫实战 78
6.3　糗事百科爬虫实战 80
6.4　微信爬虫实战 82
6.5　什么是多线程爬虫 89
6.6　多线程爬虫实战 90
6.7　小结 98
第7章　学会使用Fiddler 99
7.1　什么是Fiddler 99
7.2　爬虫与Fiddler的关系 100
7.3　Fiddler的基本原理与基本界面 100
7.4　Fiddler捕获会话功能 102
7.5　使用QuickExec命令行 104
7.6　Fiddler断点功能 106
7.7　Fiddler会话查找功能 111
7.8　Fiddler的其他功能 111
7.9　小结 113
第8章　爬虫的浏览器伪装技术 114
8.1　什么是浏览器伪装技术 114
8.2　浏览器伪装技术准备工作 115
8.3　爬虫的浏览器伪装技术实战 117
8.4　小结 121
第9章　爬虫的定向爬取技术 122
9.1　什么是爬虫的定向爬取技术 122
9.2　定向爬取的相关步骤与策略 123
9.3　定向爬取实战 124
9.4　小结 130
第三篇　框架实现篇
第10章　了解Python爬虫框架 133
10.1　什么是Python爬虫框架 133
10.2　常见的Python爬虫框架 133
10.3　认识Scrapy框架 134
10.4　认识Crawley框架 135
10.5　认识Portia框架 136
10.6　认识newspaper框架 138
10.7　认识Python-goose框架 139
10.8　小结 140
第11章　爬虫利器——Scrapy安装与配置 141
11.1　在Windows7下安装及配置Scrapy实战详解 141
11.2　在Linux（Centos）下安装及配置Scrapy实战详解 147
11.3　在MAC下安装及配置Scrapy实战详解 158
11.4　小结 161
第12章　开启Scrapy爬虫项目之旅 162
12.1　认识Scrapy项目的目录结构 162
12.2　用Scrapy进行爬虫项目管理 163
12.3　常用工具命令 166
12.4　实战：Items的编写 181
12.5　实战：Spider的编写 183
12.6　XPath基础 187
12.7　Spider类参数传递 188
12.8　用XMLFeedSpider来分析XML源 191
12.9　学会使用CSVFeedSpider 197
12.10　Scrapy爬虫多开技能 200
12.11　避免被禁止 206
12.12　小结 212
第13章　Scrapy核心架构 214
13.1　初识Scrapy架构 214
13.2　常用的Scrapy组件详解 215
13.3　Scrapy工作流 217
13.4　小结 219
第14章　Scrapy中文输出与存储 220
14.1　Scrapy的中文输出 220
14.2　Scrapy的中文存储 223
14.3　输出中文到JSON文件 225
14.4　小结 230
第15章　编写自动爬取网页的爬虫 231
15.1　实战：items的编写 231
15.2　实战：pipelines的编写 233
15.3　实战：settings的编写 234
15.4　自动爬虫编写实战 234
15.5　调试与运行 239
15.6　小结 242
第16章　CrawlSpider 243
16.1　初识CrawlSpider 243
16.2　链接提取器 244
16.3　实战：CrawlSpider实例 245
16.4　小结 249
第17章　Scrapy高级应用 250
17.1　如何在Python3中操作数据库 250
17.2　爬取内容写进MySQL 254
17.3　小结 259
第四篇　项目实战篇
第18章　博客类爬虫项目 263
18.1　博客类爬虫项目功能分析 263
18.2　博客类爬虫项目实现思路 264
18.3　博客类爬虫项目编写实战 264
18.4　调试与运行 274
18.5　小结 275
第19章　图片类爬虫项目 276
19.1　图片类爬虫项目功能分析 276
19.2　图片类爬虫项目实现思路 277
19.3　图片类爬虫项目编写实战 277
19.4　调试与运行 281
19.5　小结 282
第20章　模拟登录爬虫项目 283
20.1　模拟登录爬虫项目功能分析 283
20.2　模拟登录爬虫项目实现思路 283
20.3　模拟登录爬虫项目编写实战 284
20.4　调试与运行 292
20.5　小结 294